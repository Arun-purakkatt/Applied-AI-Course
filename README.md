# AppliedAICourse

HOW TO UTILISE APPLIEDAICOURSE 0/0
PYTHON FOR DATA SCIENCE INTRODUCTION 0/1
Lecture2.1 Python, Anaconda and relevant packages installations 23 min
Lecture2.2 Why learn Python? 04 min
Lecture2.3 Keywords and identifiers 06 min
Lecture2.4 comments, indentation and statements 09 min
Lecture2.5 Variables and data types in Python 32 min
Lecture2.6 Standard Input and Output 07 min
Lecture2.7 Operators 14 min
Lecture2.8 Control flow: if else 10 min
Lecture2.9 Control flow: while loop 16 min
Lecture2.10 Control flow: for loop 15 min
Lecture2.11 Control flow: break and continue 10 min
PYTHON FOR DATA SCIENCE: DATA STRUCTURES 0/6
Lecture3.1 Lists 38 min
Lecture3.2 Tuples part 1 10 min
Lecture3.3 Tuples part-2 04 min
Lecture3.4 Sets 16 min
Lecture3.5 Dictionary 21 min
Lecture3.6 Strings 16 min
PYTHON FOR DATA SCIENCE: FUNCTIONS 0/10
Lecture4.1 Introduction 13 min
Lecture4.2 Types of functions 25 min
Lecture4.3 Function arguments 10 min
Lecture4.4 Recursive functions 16 min
Lecture4.5 Lambda functions 08 min
Lecture4.6 Modules 07 min
Lecture4.7 Packages 06 min
Lecture4.8 File Handling 23 min
Lecture4.9 Exception Handling 15 min
Lecture4.10 Debugging Python 15 min
PYTHON FOR DATA SCIENCE: NUMPY 0/2
Lecture5.1 Numpy Introduction 41 min
Lecture5.2 Numerical operations on Numpy 41 min
PYTHON FOR DATA SCIENCE: MATPLOTLIB 0/1
Lecture6.1 Getting started with Matplotlib 20 min
PYTHON FOR DATA SCIENCE: PANDAS 0/3
Lecture7.1 Getting started with pandas 08 min
Lecture7.2 Data Frame Basics 09 min
Lecture7.3 Key Operations on Data Frames 31 min
PYTHON FOR DATA SCIENCE: COMPUTATIONAL COMPLEXITY 0/4
Lecture8.1 Space and Time Complexity: Find largest number in a list 20 min
Lecture8.2 Binary search 17 min
Lecture8.3 Find elements common in two lists 06 min
Lecture8.4 Find elements common in two lists using a Hashtable/Dict 12 min
PLOTTING FOR EXPLORATORY DATA ANALYSIS (EDA) 0/0
exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.

Lecture9.1 Introduction to IRIS dataset and 2D scatter plot 26 min
Lecture9.2 3D scatter plot 06 min
Lecture9.3 Pair plots 14 min
Lecture9.4 Limitations of Pair Plots 02 min
Lecture9.5 Histogram and Introduction to PDF(Probability Density Function) 17 min
Lecture9.6 Univariate Analysis using PDF 06 min
Lecture9.7 CDF(Cumulative Distribution Function) 15 min
Lecture9.8 Mean, Variance and Standard Deviation 17 min
Lecture9.9 Median 10 min
Lecture9.10 Percentiles and Quantiles 09 min
Lecture9.11 IQR(Inter Quartile Range) and MAD(Median Absolute Deviation) 06 min
Lecture9.12 Box-plot with Whiskers 09 min
Lecture9.13 Violin Plots 04 min
Lecture9.14 Summarizing Plots, Univariate, Bivariate and Multivariate analysis 06 min
Lecture9.15 Multivariate Probability Density, Contour Plot 09 min
Lecture9.16 Exercise: Perform EDA on Haberman dataset 04 min
LINEAR ALGEBRA 0/1
It will give you the tools to help you with the other areas of mathematics required to understand and build better intuitions for machine learning algorithms.

Lecture10.1 Why learn it ? 04 min
Lecture10.2 Introduction to Vectors(2-D, 3-D, n-D) , Row Vector and Column Vector 14 min
Lecture10.3 Dot Product and Angle between 2 Vectors 14 min
Lecture10.4 Projection and Unit Vector 05 min
Lecture10.5 Equation of a line (2-D), Plane(3-D) and Hyperplane (n-D), Plane Passing through origin, Normal to a Plane 23 min
Lecture10.6 Distance of a point from a Plane/Hyperplane, Half-Spaces 10 min
Lecture10.7 Equation of a Circle (2-D), Sphere (3-D) and Hypersphere (n-D) 07 min
Lecture10.8 Equation of an Ellipse (2-D), Ellipsoid (3-D) and Hyperellipsoid (n-D) 06 min
Lecture10.9 Square ,Rectangle 06 min
Lecture10.10 Hyper Cube,Hyper Cuboid 03 min
Lecture10.11 Revision Questions 30 min
PROBABILITY AND STATISTICS 0/26
Lecture11.1 Introduction to Probability and Statistics 17 min
Lecture11.2 Population and Sample 07 min
Lecture11.3 Gaussian/Normal Distribution and its PDF(Probability Density Function) 27 min
Lecture11.4 CDF(Cumulative Distribution function) of Gaussian/Normal distribution 11 min
Lecture11.5 Symmetric distribution, Skewness and Kurtosis 05 min
Lecture11.6 Standard normal variate (Z) and standardization 05 min
Lecture11.7 Kernel density estimation 07 min
Lecture11.8 Sampling distribution & Central Limit theorem 19 min
Lecture11.9 Q-Q plot:How to test if a random variable is normally distributed or not? 23 min
Lecture11.10 Discrete and Continuous Uniform distributions 13 min
Lecture11.11 How to randomly sample data points (Uniform Distribution) 10 min
Lecture11.12 Bernoulli and Binomial Distribution 11 min
Lecture11.13 Log Normal Distribution 12 min
Lecture11.14 Power law distribution 12 min
Lecture11.15 Box cox transform 12 min
Lecture11.16 Co-variance 14 min
Lecture11.17 Pearson Correlation Coefficient 13 min
Lecture11.18 Spearman Rank Correlation Coefficient 07 min
Lecture11.19 Correlation vs Causation 03 min
Lecture11.20 Confidence interval (C.I) Introduction 08 min
Lecture11.21 Computing confidence interval given the underlying distribution 11 min
Lecture11.22 C.I for mean of a normal random variable 14 min
Lecture11.23 Confidence interval using bootstrapping 17 min
Lecture11.24 Hypothesis testing methodology, Null-hypothesis, p-value 16 min
Lecture11.25 Resampling and permutation test 15 min
Lecture11.26 K-S Test for similarity of two distributions 15 min
Lecture11.27 Code Snippet K-S Test 06 min
Lecture11.28 Hypothesis Testing Intution with coin toss example 27 min
Lecture11.29 Hypothesis testing Mean differences Example 18 min
Lecture11.30 Resampling and Permutation test for Mean difference example 19 min
Lecture11.31 Revision Questions 30 min
INTERVIEW QUESTIONS ON PROBABILITY AND STATISTICS 0/0
Lecture12.1 Questions & Answers 30 min
DIMENSIONALITY REDUCTION AND VISUALIZATION: 0/0
In machine learning and statistics, dimensionality reduction or dimension reduction is the process of reducing the number of random variables under consideration, via obtaining a set of principal variables. It can be divided into feature selection and feature extraction.

Lecture13.1 What is Dimensionality reduction? 03 min
Lecture13.2 Row Vector and Column Vector 05 min
Lecture13.3 How to represent a data set? 04 min
Lecture13.4 How to represent a dataset as a Matrix. 07 min
Lecture13.5 Data Preprocessing: Feature Normalisation 20 min
Lecture13.6 Mean of a data matrix 06 min
Lecture13.7 Data Preprocessing: Column Standardization 16 min
Lecture13.8 Co-variance of a Data Matrix 24 min
Lecture13.9 MNIST dataset (784 dimensional) 20 min
Lecture13.10 Code to Load MNIST Data Set 12 min
PCA(PRINCIPAL COMPONENT ANALYSIS) 0/0
Lecture14.1 Why learn PCA? 04 min
Lecture14.2 Geometric intuition of PCA 14 min
Lecture14.3 Mathematical objective function of PCA 13 min
Lecture14.4 Alternative formulation of PCA: Distance minimization 10 min
Lecture14.5 Eigen values and Eigen vectors (PCA): Dimensionality reduction 23 min
Lecture14.6 PCA for Dimensionality Reduction and Visualization 10 min
Lecture14.7 Visualize MNIST dataset 05 min
Lecture14.8 Limitations of PCA 05 min
Lecture14.9 PCA Code example 19 min
Lecture14.10 PCA for dimensionality reduction (not-visualization) 15 min
(T-SNE)T-DISTRIBUTED STOCHASTIC NEIGHBOURHOOD EMBEDDING 0/1
Lecture15.1 What is t-SNE? 07 min
Lecture15.2 Neighborhood of a point, Embedding 07 min
Lecture15.3 Geometric intuition of t-SNE 09 min
Lecture15.4 Crowding Problem 08 min
Lecture15.5 How to apply t-SNE and interpret its output 38 min
Lecture15.6 t-SNE on MNIST 07 min
Lecture15.7 Code example of t-SNE 09 min
Lecture15.8 Revision Questions 30 min
INTERVIEW QUESTIONS ON DIMENSIONALITY REDUCTION 0/0
Lecture16.1 Questions & Answers 30 min
REAL WORLD PROBLEM: PREDICT RATING GIVEN PRODUCT REVIEWS ON AMAZON 0/18
Lecture17.1 Dataset overview: Amazon Fine Food reviews(EDA) 23 min
Lecture17.2 Data Cleaning: Deduplication 15 min
Lecture17.3 Why convert text to a vector? 14 min
Lecture17.4 Bag of Words (BoW) 18 min
Lecture17.5 Text Preprocessing: Stemming, Stop-word removal, Tokenization, Lemmatization. 15 min
Lecture17.6 uni-gram, bi-gram, n-grams. 09 min
Lecture17.7 tf-idf (term frequency- inverse document frequency) 22 min
Lecture17.8 Why use log in IDF? 14 min
Lecture17.9 Word2Vec. 16 min
Lecture17.10 Avg-Word2Vec, tf-idf weighted Word2Vec 09 min
Lecture17.11 Bag of Words( Code Sample) 19 min
Lecture17.12 Text Preprocessing( Code Sample) 11 min
Lecture17.13 Bi-Grams and n-grams (Code Sample) 05 min
Lecture17.14 TF-IDF (Code Sample) 06 min
Lecture17.15 Word2Vec (Code Sample) 12 min
Lecture17.16 Avg-Word2Vec and TFIDF-Word2Vec (Code Sample) 02 min
Lecture17.17 Exercise: t-SNE visualization of Amazon reviews with polarity based color-coding 06 min
Lecture17.18 Assignment 30 min
CLASSIFICATION AND REGRESSION MODELS: K-NEAREST NEIGHBORS 0/33
Lecture18.1 How “Classification” works? 10 min
Lecture18.2 Data matrix notation 07 min
Lecture18.3 Classification vs Regression (examples) 06 min
Lecture18.4 K-Nearest Neighbours Geometric intuition with a toy example 11 min
Lecture18.5 Failure cases of KNN 07 min
Lecture18.6 Distance measures: Euclidean(L2) , Manhattan(L1), Minkowski, Hamming 20 min
Lecture18.7 Cosine Distance & Cosine Similarity 19 min
Lecture18.8 How to measure the effectiveness of k-NN? 16 min
Lecture18.9 Test/Evaluation time and space complexity 12 min
Lecture18.10 KNN Limitations 09 min
Lecture18.11 Decision surface for K-NN as K changes 23 min
Lecture18.12 Overfitting and Underfitting 12 min
Lecture18.13 Need for Cross validation 22 min
Lecture18.14 K-fold cross validation 17 min
Lecture18.15 Visualizing train, validation and test datasets 13 min
Lecture18.16 How to determine overfitting and underfitting? 19 min
Lecture18.17 Time based splitting 19 min
Lecture18.18 k-NN for regression 05 min
Lecture18.19 Weighted k-NN 08 min
Lecture18.20 Voronoi diagram 04 min
Lecture18.21 Binary search tree 16 min
Lecture18.22 How to build a kd-tree 17 min
Lecture18.23 Find nearest neighbours using kd-tree 13 min
Lecture18.24 Limitations of Kd tree 09 min
Lecture18.25 Extensions 03 min
Lecture18.26 Hashing vs LSH 10 min
Lecture18.27 LSH for cosine similarity 40 min
Lecture18.28 LSH for euclidean distance 13 min
Lecture18.29 Probabilistic class label 08 min
Lecture18.30 Code Sample:Decision boundary . 23 min
Lecture18.31 Code Sample:Cross Validation 13 min
Lecture18.32 Exercise: Apply k-NN on Amazon reviews dataset 05 min
Lecture18.33 Revision Questions 30 min
INTERVIEW QUESTIONS ON K-NN(K NEAREST NEIGHBOUR) 0/0
Lecture19.1 Questions & Answers 30 min
CLASSIFICATION ALGORITHMS IN VARIOUS SITUATIONS 0/21
Lecture20.1 Introduction 05 min
Lecture20.2 Imbalanced vs balanced dataset 23 min
Lecture20.3 Multi-class classification 12 min
Lecture20.4 k-NN, given a distance or similarity matrix 09 min
Lecture20.5 Train and test set differences 22 min
Lecture20.6 Impact of outliers 07 min
Lecture20.7 Local outlier Factor (Simple solution :Mean distance to Knn) 13 min
Lecture20.8 k distance 04 min
Lecture20.9 Reachability-Distance(A,B) 08 min
Lecture20.10 Local reachability-density(A) 09 min
Lecture20.11 Local outlier Factor(A) 21 min
Lecture20.12 Impact of Scale & Column standardization 12 min
Lecture20.13 Interpretability 12 min
Lecture20.14 Feature Importance and Forward Feature selection 22 min
Lecture20.15 Handling categorical and numerical features 24 min
Lecture20.16 Handling missing values by imputation 21 min
Lecture20.17 curse of dimensionality 27 min
Lecture20.18 Bias-Variance tradeoff 24 min
Lecture20.19 Intuitive understanding of bias-variance. 06 min
Lecture20.20 Revision Questions 30 min
Lecture20.21 best and wrost case of algorithm 06 min
PERFORMANCE MEASUREMENT OF MODELS 0/9
Lecture21.1 Accuracy 15 min
Lecture21.2 Confusion matrix, TPR, FPR, FNR, TNR 25 min
Lecture21.3 Precision and recall, F1-score 10 min
Lecture21.4 Receiver Operating Characteristic Curve (ROC) curve and AUC 19 min
Lecture21.5 Log-loss 12 min
Lecture21.6 R-Squared/Coefficient of determination 14 min
Lecture21.7 Median absolute deviation (MAD) 05 min
Lecture21.8 Revision Questions 30 min
Lecture21.9 Distribution of errors 07 min
INTERVIEW QUESTIONS ON PERFORMANCE MEASUREMENT MODELS 0/0
Lecture22.1 Questions & Answers 30 min
NAIVE BAYES 0/22
Lecture23.1 Conditional probability 13 min
Lecture23.2 Independent vs Mutually exclusive events 06 min
Lecture23.3 Bayes Theorem with examples 18 min
Lecture23.4 Exercise problems on Bayes Theorem 30 min
Lecture23.5 Naive Bayes algorithm 26 min
Lecture23.6 Toy example: Train and test stages 26 min
Lecture23.7 Naive Bayes on Text data 16 min
Lecture23.8 Laplace/Additive Smoothing 24 min
Lecture23.9 Log-probabilities for numerical stability 11 min
Lecture23.10 Bias and Variance tradeoff 14 min
Lecture23.11 Feature importance and interpretability 10 min
Lecture23.12 Imbalanced data 14 min
Lecture23.13 Outliers 06 min
Lecture23.14 Missing values 03 min
Lecture23.15 Handling Numerical features (Gaussian NB) 13 min
Lecture23.16 Multiclass classification 02 min
Lecture23.17 Similarity or Distance matrix 03 min
Lecture23.18 Large dimensionality 02 min
Lecture23.19 Best and worst cases 08 min
Lecture23.20 Code example 07 min
Lecture23.21 Exercise: Apply Naive Bayes to Amazon reviews 06 min
Lecture23.22 Revision Questions 30 min
LOGISTIC REGRESSION 0/18
Lecture24.1 Geometric intuition of Logistic Regression 31 min
Lecture24.2 Sigmoid function: Squashing 37 min
Lecture24.3 Mathematical formulation of Objective function 24 min
Lecture24.4 Weight vector 11 min
Lecture24.5 L2 Regularization: Overfitting and Underfitting 26 min
Lecture24.6 L1 regularization and sparsity 11 min
Lecture24.7 Probabilistic Interpretation: Gaussian Naive Bayes 19 min
Lecture24.8 Loss minimization interpretation 24 min
Lecture24.9 hyperparameters and random search 16 min
Lecture24.10 Column Standardization 05 min
Lecture24.11 Feature importance and Model interpretability 14 min
Lecture24.12 Collinearity of features 14 min
Lecture24.13 Test/Run time space and time complexity 10 min
Lecture24.14 Real world cases 11 min
Lecture24.15 Non-linearly separable data & feature engineering 28 min
Lecture24.16 Code sample: Logistic regression, GridSearchCV, RandomSearchCV 23 min
Lecture24.17 Exercise: Apply Logistic regression to Amazon reviews dataset. 06 min
Lecture24.18 Extensions to Generalized linear models 09 min
LINEAR REGRESSION 0/4
Lecture25.1 Geometric intuition of Linear Regression 13 min
Lecture25.2 Mathematical formulation 14 min
Lecture25.3 Real world Cases 08 min
Lecture25.4 Code sample for Linear Regression 13 min
SOLVING OPTIMIZATION PROBLEMS 0/13
Lecture26.1 Differentiation 29 min
Lecture26.2 Revision Questions 30 min
Lecture26.3 Online differentiation tools 08 min
Lecture26.4 Maxima and Minima 12 min
Lecture26.5 Vector calculus: Grad 10 min
Lecture26.6 Gradient descent: geometric intuition 19 min
Lecture26.7 Learning rate 08 min
Lecture26.8 Gradient descent for linear regression 08 min
Lecture26.9 SGD algorithm 09 min
Lecture26.10 Constrained Optimization & PCA 14 min
Lecture26.11 Logistic regression formulation revisited 06 min
Lecture26.12 Why L1 regularization creates sparsity? 17 min
Lecture26.13 Exercise: Implement SGD for linear regression 06 min
Lecture26.14 Revision questions 30 min
INTERVIEW QUESTIONS ON LOGISTIC REGRESSION AND LINEAR REGRESSION 0/0
Lecture27.1 Questions & Answers 30 min
SUPPORT VECTOR MACHINES (SVM) 0/16
Lecture28.1 Geometric Intution 20 min
Lecture28.2 Mathematical derivation 32 min
Lecture28.3 Why we take values +1 and and -1 for Support vector planes 09 min
Lecture28.4 Loss function (Hinge Loss) based interpretation 18 min
Lecture28.5 Dual form of SVM formulation 16 min
Lecture28.6 kernel trick 10 min
Lecture28.7 kernel Polynomial 11 min
Lecture28.8 RBF-Kernel 21 min
Lecture28.9 Domain specific Kernels 06 min
Lecture28.10 Train and run time complexities 08 min
Lecture28.11 nu-SVM: control errors and support vectors 06 min
Lecture28.12 SVM Regression 08 min
Lecture28.13 Cases 09 min
Lecture28.14 Code Sample 14 min
Lecture28.15 Exercise: Apply SVM to Amazon reviews dataset 04 min
Lecture28.16 Revision Questions 30 min
INTERVIEW QUESTIONS ON SUPPORT VECTOR MACHINE 0/0
Lecture29.1 Questions & Answers 30 min
DECISION TREES 0/16
Lecture30.1 Geometric Intuition of decision tree: Axis parallel hyperplanes 17 min
Lecture30.2 Sample Decision tree 08 min
Lecture30.3 Building a decision Tree:Entropy 19 min
Lecture30.4 Building a decision Tree:Information Gain 10 min
Lecture30.5 Building a decision Tree: Gini Impurity 07 min
Lecture30.6 Building a decision Tree: Constructing a DT 21 min
Lecture30.7 Building a decision Tree: Splitting numerical features 08 min
Lecture30.8 Feature standardization 04 min
Lecture30.9 Building a decision Tree:Categorical features with many possible values 07 min
Lecture30.10 Overfitting and Underfitting 08 min
Lecture30.11 Train and Run time complexity 07 min
Lecture30.12 Regression using Decision Trees 09 min
Lecture30.13 Cases 12 min
Lecture30.14 Code Samples 09 min
Lecture30.15 Exercise: Decision Trees on Amazon reviews dataset 03 min
Lecture30.16 Revision Questions 30 min
INTERVIEW QUESTIONS ON DECISION TREES 0/0
Lecture31.1 Questions & Answers 30 min
ENSEMBLE MODELS 0/20
Lecture32.1 What are ensembles? 06 min
Lecture32.2 Bootstrapped Aggregation (Bagging) Intuition 17 min
Lecture32.3 Random Forest and their construction 15 min
Lecture32.4 Bias-Variance tradeoff 07 min
Lecture32.5 Train and run time complexity 09 min
Lecture32.6 Bagging:Code Sample 04 min
Lecture32.7 Extremely randomized trees 08 min
Lecture32.8 Random Tree :Cases 06 min
Lecture32.9 Boosting Intuition 17 min
Lecture32.10 Residuals, Loss functions and gradients 13 min
Lecture32.11 Gradient Boosting 10 min
Lecture32.12 Regularization by Shrinkage 08 min
Lecture32.13 Train and Run time complexity 06 min
Lecture32.14 XGBoost: Boosting + Randomization 14 min
Lecture32.15 AdaBoost: geometric intuition 07 min
Lecture32.16 Stacking models 22 min
Lecture32.17 Cascading classifiers 15 min
Lecture32.18 Kaggle competitions vs Real world 09 min
Lecture32.19 Exercise: Apply GBDT and RF to Amazon reviews dataset. 04 min
Lecture32.20 Revision Questions 30 min
FEATURIZATION AND FEATURE ENGINEERING. 0/18
Lecture33.1 Introduction 17 min
Lecture33.2 Moving window for Time Series Data 25 min
Lecture33.3 Fourier decomposition 22 min
Lecture33.4 Deep learning features: LSTM 08 min
Lecture33.5 Image histogram 23 min
Lecture33.6 Keypoints: SIFT. 10 min
Lecture33.7 Deep learning features: CNN 04 min
Lecture33.8 Relational data 10 min
Lecture33.9 Graph data 12 min
Lecture33.10 Indicator variables 07 min
Lecture33.11 Feature binning 14 min
Lecture33.12 Interaction variables 08 min
Lecture33.13 Mathematical transforms 04 min
Lecture33.14 Model specific featurizations 09 min
Lecture33.15 Feature orthogonality 11 min
Lecture33.16 Domain specific featurizations 04 min
Lecture33.17 Feature slicing 10 min
Lecture33.18 Kaggle Winners solutions 07 min
MISCELLANEOUS TOPICS 0/8
Lecture34.1 Calibration of Models:Need for calibration 08 min
Lecture34.2 Calibration Plots. 17 min
Lecture34.3 Platt’s Calibration/Scaling. 08 min
Lecture34.4 Isotonic Regression 11 min
Lecture34.5 Code Samples 04 min
Lecture34.6 Modeling in the presence of outliers: RANSAC 13 min
Lecture34.7 Productionizing models 17 min
Lecture34.8 Retraining models periodically. 08 min
Lecture34.9 A/B testing. 22 min
Lecture34.10 Data Science Life cycle 17 min
UNSUPERVISED LEARNING/CLUSTERING 0/14
Lecture35.1 What is Clustering? 10 min
Lecture35.2 Unsupervised learning 04 min
Lecture35.3 Applications 16 min
Lecture35.4 Metrics for Clustering 13 min
Lecture35.5 K-Means: Geometric intuition, Centroids 08 min
Lecture35.6 K-Means: Mathematical formulation: Objective function 11 min
Lecture35.7 K-Means Algorithm. 11 min
Lecture35.8 How to initialize: K-Means++ 24 min
Lecture35.9 Failure cases/Limitations 11 min
Lecture35.10 K-Medoids 19 min
Lecture35.11 Determining the right K 05 min
Lecture35.12 Code Samples 07 min
Lecture35.13 Time and space complexity 04 min
Lecture35.14 Exercise: Clustering the Amazon reviews 05 min
HIERARCHICAL CLUSTERING TECHNIQUE 0/7
Lecture36.1 Agglomerative & Divisive, Dendrograms 13 min
Lecture36.2 Agglomerative Clustering 09 min
Lecture36.3 Proximity methods: Advantages and Limitations. 24 min
Lecture36.4 Time and Space Complexity 04 min
Lecture36.5 Limitations of Hierarchical Clustering 05 min
Lecture36.6 Code sample 03 min
Lecture36.7 Exercise: Amazon food reviews 03 min
DBSCAN (DENSITY BASED CLUSTERING) TECHNIQUE 0/11
Lecture37.1 Density based clustering 05 min
Lecture37.2 MinPts and Eps: Density 06 min
Lecture37.3 Core, Border and Noise points 07 min
Lecture37.4 Density edge and Density connected points. 06 min
Lecture37.5 DBSCAN Algorithm 11 min
Lecture37.6 Hyper Parameters: MinPts and Eps 10 min
Lecture37.7 Advantages and Limitations of DBSCAN 10 min
Lecture37.8 Time and Space Complexity 03 min
Lecture37.9 Code samples. 03 min
Lecture37.10 Exercise: Amazon Food reviews 03 min
Lecture37.11 Revision Questions 30 min
RECOMMENDER SYSTEMS AND MATRIX FACTORIZATION 0/16
Lecture38.1 Problem formulation: IMDB Movie reviews 23 min
Lecture38.2 Content based vs Collaborative Filtering 11 min
Lecture38.3 Similarity based Algorithms 16 min
Lecture38.4 Matrix Factorization: PCA, SVD 23 min
Lecture38.5 Matrix Factorization: NMF 03 min
Lecture38.6 Matrix Factorization for Collaborative filtering 23 min
Lecture38.7 Matrix Factorization for feature engineering 09 min
Lecture38.8 Clustering as MF 21 min
Lecture38.9 Hyperparameter tuning 10 min
Lecture38.10 Matrix Factorization for recommender systems: Netflix Prize Solution 30 min
Lecture38.11 Cold Start problem 06 min
Lecture38.12 Word vectors as MF 20 min
Lecture38.13 Eigen-Faces 15 min
Lecture38.14 Code example. 11 min
Lecture38.15 Exercise: Word Vectors using Truncated SVD. 07 min
Lecture38.16 Revision Questions 30 min
INTERVIEW QUESTIONS ON RECOMMENDER SYSTEMS AND MATRIX FACTORIZATION. 0/0
Lecture39.1 Questions & Answers 30 min
CASE STUDY 2: PERSONALIZED CANCER DIAGNOSIS 0/21
Lecture40.1 Business/Real world problem : Overview 13 min
Lecture40.2 Business objectives and constraints. 11 min
Lecture40.3 ML problem formulation :Data 05 min
Lecture40.4 ML problem formulation: Mapping real world to ML problem. 19 min
Lecture40.5 ML problem formulation :Train, CV and Test data construction 04 min
Lecture40.6 Exploratory Data Analysis:Reading data & preprocessing 07 min
Lecture40.7 Exploratory Data Analysis:Distribution of Class-labels 07 min
Lecture40.8 Exploratory Data Analysis: “Random” Model 19 min
Lecture40.9 Univariate Analysis:Gene feature 34 min
Lecture40.10 Univariate Analysis:Variation Feature 19 min
Lecture40.11 Univariate Analysis:Text feature 15 min
Lecture40.12 Machine Learning Models:Data preparation 08 min
Lecture40.13 Baseline Model: Naive Bayes 23 min
Lecture40.14 K-Nearest Neighbors Classification 09 min
Lecture40.15 Logistic Regression with class balancing 10 min
Lecture40.16 Logistic Regression without class balancing 04 min
Lecture40.17 Linear-SVM. 06 min
Lecture40.18 Random-Forest with one-hot encoded features 07 min
Lecture40.19 Random-Forest with response-coded features 06 min
Lecture40.20 Stacking Classifier 08 min
Lecture40.21 Majority Voting classifier 05 min
Lecture40.22 Assignments. 05 min
CASE STUDY 3:TAXI DEMAND PREDICTION IN NEW YORK CITY 0/28
Lecture41.1 Business/Real world problem Overview 09 min
Lecture41.2 Objectives and Constraints 11 min
Lecture41.3 Mapping to ML problem :Data 08 min
Lecture41.4 Mapping to ML problem :dask dataframes 11 min
Lecture41.5 Mapping to ML problem :Fields/Features. 06 min
Lecture41.6 Mapping to ML problem :Time series forecasting/Regression 08 min
Lecture41.7 Mapping to ML problem :Performance metrics 06 min
Lecture41.8 Data Cleaning :Latitude and Longitude data 04 min
Lecture41.9 Data Cleaning :Trip Duration. 07 min
Lecture41.10 Data Cleaning :Speed. 05 min
Lecture41.11 Data Cleaning :Distance. 02 min
Lecture41.12 Data Cleaning :Fare 06 min
Lecture41.13 Data Cleaning :Remove all outliers/erroneous points 03 min
Lecture41.14 Data Preparation:Clustering/Segmentation 19 min
Lecture41.15 Data Preparation:Time binning 05 min
Lecture41.16 Data Preparation:Smoothing time-series data. 05 min
Lecture41.17 Data Preparation:Smoothing time-series data cont.. 02 min
Lecture41.18 Data Preparation: Time series and Fourier transforms. 13 min
Lecture41.19 Ratios and previous-time-bin values 09 min
Lecture41.20 Simple moving average 08 min
Lecture41.21 Weighted Moving average. 05 min
Lecture41.22 Exponential weighted moving average 06 min
Lecture41.23 Results. 04 min
Lecture41.24 Regression models :Train-Test split & Features 08 min
Lecture41.25 Linear regression. 03 min
Lecture41.26 Random Forest regression 04 min
Lecture41.27 Xgboost Regression 02 min
Lecture41.28 Model comparison 06 min
Lecture41.29 Assignment. 06 min
CASE STUDY 4: MICROSOFT MALWARE DETECTION 0/20
Lecture42.1 Business/real world problem :Problem definition 06 min
Lecture42.2 Business/real world problem :Objectives and constraints 07 min
Lecture42.3 Machine Learning problem mapping :Data overview. 13 min
Lecture42.4 Machine Learning problem mapping :ML problem 12 min
Lecture42.5 Machine Learning problem mapping :Train and test splitting 04 min
Lecture42.6 Exploratory Data Analysis :Class distribution. 03 min
Lecture42.7 Exploratory Data Analysis :Feature extraction from byte files 08 min
Lecture42.8 Exploratory Data Analysis :Multivariate analysis of features from byte files 03 min
Lecture42.9 Exploratory Data Analysis :Train-Test class distribution 03 min
Lecture42.10 ML models – using byte files only :Random Model 11 min
Lecture42.11 k-NN 07 min
Lecture42.12 Logistic regression 05 min
Lecture42.13 Random Forest and Xgboost 07 min
Lecture42.14 ASM Files :Feature extraction & Multi-threading. 11 min
Lecture42.15 File-size feature 02 min
Lecture42.16 Univariate analysis 03 min
Lecture42.17 t-SNE analysis. 02 min
Lecture42.18 ML models on ASM file features 07 min
Lecture42.19 Models on all features :t-SNE 02 min
Lecture42.20 Models on all features :RandomForest and Xgboost 04 min
Lecture42.21 Assignments. 04 min
CASE STUDY 5:NETFLIX MOVIE RECOMMENDATION SYSTEM 0/27
Lecture43.1 Business/Real world problem:Problem definition 06 min
Lecture43.2 Objectives and constraints 07 min
Lecture43.3 Mapping to an ML problem:Data overview. 04 min
Lecture43.4 Mapping to an ML problem:ML problem formulation 05 min
Lecture43.5 Exploratory Data Analysis:Data preprocessing 07 min
Lecture43.6 Exploratory Data Analysis:Temporal Train-Test split. 06 min
Lecture43.7 Exploratory Data Analysis:Preliminary data analysis. 15 min
Lecture43.8 Exploratory Data Analysis:Sparse matrix representation 08 min
Lecture43.9 Exploratory Data Analysis:Average ratings for various slices 08 min
Lecture43.10 Exploratory Data Analysis:Cold start problem 05 min
Lecture43.11 Computing Similarity matrices:User-User similarity matrix 20 min
Lecture43.12 Computing Similarity matrices:Movie-Movie similarity 06 min
Lecture43.13 Computing Similarity matrices:Does movie-movie similarity work? 06 min
Lecture43.14 ML Models:Surprise library 06 min
Lecture43.15 Overview of the modelling strategy. 08 min
Lecture43.16 Data Sampling. 05 min
Lecture43.17 Google drive with intermediate files 02 min
Lecture43.18 Featurizations for regression. 11 min
Lecture43.19 Data transformation for Surprise. 02 min
Lecture43.20 Xgboost with 13 features 06 min
Lecture43.21 Surprise Baseline model. 09 min
Lecture43.22 Xgboost + 13 features +Surprise baseline model 04 min
Lecture43.23 Surprise KNN predictors 15 min
Lecture43.24 Matrix Factorization models using Surprise 05 min
Lecture43.25 SVD ++ with implicit feedback 11 min
Lecture43.26 Final models with all features and predictors. 04 min
Lecture43.27 Comparison between various models. 04 min
Lecture43.28 Comparison between various models. 04 min
CASE STUDY 6: STACKOVERFLOW TAG PREDICTOR 0/17
Lecture44.1 Business/Real world problem 10 min
Lecture44.2 Business objectives and constraints 05 min
Lecture44.3 Mapping to an ML problem: Data overview 04 min
Lecture44.4 Mapping to an ML problem:ML problem formulation. 05 min
Lecture44.5 Mapping to an ML problem:Performance metrics. 21 min
Lecture44.6 Hamming loss 07 min
Lecture44.7 EDA:Data Loading 13 min
Lecture44.8 EDA:Analysis of tags 11 min
Lecture44.9 EDA:Data Preprocessing 11 min
Lecture44.10 Data Modeling : Multi label Classification 18 min
Lecture44.11 Data preparation. 08 min
Lecture44.12 Train-Test Split 02 min
Lecture44.13 Featurization 06 min
Lecture44.14 Logistic regression: One VS Rest 07 min
Lecture44.15 Sampling data and tags+Weighted models. 04 min
Lecture44.16 Logistic regression revisited 04 min
Lecture44.17 Why not use advanced techniques 03 min
Lecture44.18 Assignments. 05 min
CASE STUDY 7: QUORA QUESTION PAIR SIMILARITY PROBLEM 0/16
Lecture45.1 Business/Real world problem : Problem definition 06 min
Lecture45.2 Business objectives and constraints. 05 min
Lecture45.3 Mapping to an ML problem : Data overview 05 min
Lecture45.4 Mapping to an ML problem : ML problem and performance metric. 04 min
Lecture45.5 Mapping to an ML problem : Train-test split 05 min
Lecture45.6 EDA: Basic Statistics. 07 min
Lecture45.7 EDA: Basic Feature Extraction 06 min
Lecture45.8 EDA: Text Preprocessing 10 min
Lecture45.9 EDA: Advanced Feature Extraction 31 min
Lecture45.10 EDA: Feature analysis. 09 min
Lecture45.11 EDA: Data Visualization: T-SNE. 03 min
Lecture45.12 EDA: TF-IDF weighted Word2Vec featurization. 06 min
Lecture45.13 ML Models :Loading Data 06 min
Lecture45.14 ML Models: Random Model 07 min
Lecture45.15 ML Models : Logistic Regression and Linear SVM 11 min
Lecture45.16 ML Models : XGBoost 06 min
Lecture45.17 Assignments 04 min
CASE STUDY 8: AMAZON FASHION DISCOVERY ENGINE 0/27
Lecture46.1 Problem Statement: Recommend similar apparel products in e-commerce using product descriptions and Images 12 min
Lecture46.2 Plan of action 07 min
Lecture46.3 Amazon product advertising API 10 min
Lecture46.4 Data folders and paths 06 min
Lecture46.5 Overview of the data and Terminology 12 min
Lecture46.6 Data cleaning and understanding:Missing data in various features 22 min
Lecture46.7 Understand duplicate rows 09 min
Lecture46.8 Remove duplicates : Part 1 12 min
Lecture46.9 Remove duplicates: Part 2 15 min
Lecture46.10 Text Pre-Processing: Tokenization and Stop-word removal 10 min
Lecture46.11 Stemming 04 min
Lecture46.12 Text based product similarity :Converting text to an n-D vector: bag of words 14 min
Lecture46.13 Code for bag of words based product similarity 26 min
Lecture46.14 TF-IDF: featurizing text based on word-importance 17 min
Lecture46.15 Code for TF-IDF based product similarity 10 min
Lecture46.16 Code for IDF based product similarity 09 min
Lecture46.17 Text Semantics based product similarity: Word2Vec(featurizing text based on semantic similarity) 19 min
Lecture46.18 Code for Average Word2Vec product similarity 15 min
Lecture46.19 TF-IDF weighted Word2Vec 09 min
Lecture46.20 Code for IDF weighted Word2Vec product similarity 06 min
Lecture46.21 Weighted similarity using brand and color 09 min
Lecture46.22 Code for weighted similarity 07 min
Lecture46.23 Building a real world solution 05 min
Lecture46.24 Deep learning based visual product similarity:ConvNets: How to featurize an image: edges, shapes, parts 11 min
Lecture46.25 Using Keras + Tensorflow to extract features 08 min
Lecture46.26 Visual similarity based product similarity 06 min
Lecture46.27 Measuring goodness of our solution :A/B testing 07 min
Lecture46.28 Exercise :Build a weighted Nearest neighbor model using Visual, Text, Brand and Color 09 min
DEEP LEARNING:NEURAL NETWORKS. 0/14
Lecture47.1 History of Neural networks and Deep Learning. 25 min
Lecture47.2 How Biological Neurons work? 10 min
Lecture47.3 Growth of biological neural networks 16 min
Lecture47.4 Diagrammatic representation: Logistic Regression and Perceptron 17 min
Lecture47.5 Multi-Layered Perceptron (MLP). 23 min
Lecture47.6 Notation 18 min
Lecture47.7 Training a single-neuron model. 28 min
Lecture47.8 Training an MLP: Chain Rule 40 min
Lecture47.9 Training an MLP:Memoization 14 min
Lecture47.10 Backpropagation. 26 min
Lecture47.11 Activation functions 17 min
Lecture47.12 Vanishing Gradient problem. 23 min
Lecture47.13 Bias-Variance tradeoff. 10 min
Lecture47.14 Decision surfaces: Playground 15 min
DEEP LEARNING: DEEP MULTI-LAYER PERCEPTRONS 0/21
Lecture48.1 Deep Multi-layer perceptrons:1980s to 2010s 16 min
Lecture48.2 Dropout layers & Regularization. 21 min
Lecture48.3 Rectified Linear Units (ReLU). 28 min
Lecture48.4 Weight initialization. 24 min
Lecture48.5 Batch Normalization. 21 min
Lecture48.6 Optimizers:Hill-descent analogy in 2D 19 min
Lecture48.7 Optimizers:Hill descent in 3D and contours. 13 min
Lecture48.8 SGD Recap 18 min
Lecture48.9 Batch SGD with momentum. 25 min
Lecture48.10 Nesterov Accelerated Gradient (NAG) 08 min
Lecture48.11 Optimizers:AdaGrad 15 min
Lecture48.12 Optimizers : Adadelta andRMSProp 10 min
Lecture48.13 Adam 11 min
Lecture48.14 Which algorithm to choose when? 05 min
Lecture48.15 Gradient Checking and clipping 10 min
Lecture48.16 Softmax and Cross-entropy for multi-class classification. 25 min
Lecture48.17 How to train a Deep MLP? 08 min
Lecture48.18 Auto Encoders. 27 min
Lecture48.19 Word2Vec :CBOW 19 min
Lecture48.20 Word2Vec: Skip-gram 14 min
Lecture48.21 Word2Vec :Algorithmic Optimizations. 12 min
DEEP LEARNING: TENSORFLOW AND KERAS. 0/14
Lecture49.1 Tensorflow and Keras overview 23 min
Lecture49.2 GPU vs CPU for Deep Learning. 23 min
Lecture49.3 Google Colaboratory. 05 min
Lecture49.4 Install TensorFlow 06 min
Lecture49.5 Online documentation and tutorials 06 min
Lecture49.6 Softmax Classifier on MNIST dataset. 32 min
Lecture49.7 MLP: Initialization 11 min
Lecture49.8 Model 1: Sigmoid activation 22 min
Lecture49.9 Model 2: ReLU activation. 06 min
Lecture49.10 Model 3: Batch Normalization. 08 min
Lecture49.11 Model 4 : Dropout. 05 min
Lecture49.12 MNIST classification in Keras. 18 min
Lecture49.13 Hyperparameter tuning in Keras. 11 min
Lecture49.14 Exercise: Try different MLP architectures on MNIST dataset. 05 min
DEEP LEARNING: CONVOLUTIONAL NEURAL NETS. 0/19
Lecture50.1 Biological inspiration: Visual Cortex 17 min
Lecture50.2 Convolution:Edge Detection on images. 28 min
Lecture50.3 Convolution:Padding and strides 19 min
Lecture50.4 Convolution over RGB images. 11 min
Lecture50.5 Convolutional layer. 23 min
Lecture50.6 Max-pooling. 12 min
Lecture50.7 CNN Training: Optimization 09 min
Lecture50.8 Example CNN: LeNet [1998] 11 min
Lecture50.9 ImageNet dataset. 06 min
Lecture50.10 Data Augmentation. 07 min
Lecture50.11 Convolution Layers in Keras 17 min
Lecture50.12 AlexNet 13 min
Lecture50.13 VGGNet 11 min
Lecture50.14 Residual Network. 22 min
Lecture50.15 Inception Network. 19 min
Lecture50.16 What is Transfer learning. 23 min
Lecture50.17 Code example: Cats vs Dogs. 15 min
Lecture50.18 Code Example: MNIST dataset. 06 min
Lecture50.19 Assignment: Try various CNN networks on MNIST dataset. 04 min
DEEP LEARNING: LONG SHORT-TERM MEMORY (LSTMS) 0/11
Lecture51.1 Why RNNs? 23 min
Lecture51.2 Recurrent Neural Network. 29 min
Lecture51.3 Training RNNs: Backprop. 16 min
Lecture51.4 Types of RNNs. 14 min
Lecture51.5 Need for LSTM/GRU. 10 min
Lecture51.6 LSTM. 34 min
Lecture51.7 GRUs. 07 min
Lecture51.8 Deep RNN. 07 min
Lecture51.9 Bidirectional RNN. 12 min
Lecture51.10 Code example : IMDB Sentiment classification 33 min
Lecture51.11 Exercise: Amazon Fine Food reviews LSTM model. 04 min
INTERVIEW QUESTIONS ON DEEP LEARNING 0/1
Lecture52.1 Questions and Answers 30 min
CASE STUDY 9: SELF DRIVING CAR 0/13
Lecture53.1 Self Driving Car :Problem definition. 14 min
Lecture53.2 Datasets. 09 min
Lecture53.3 Data understanding & Analysis :Files and folders. 04 min
Lecture53.4 Dash-cam images and steering angles. 05 min
Lecture53.5 Split the dataset: Train vs Test 03 min
Lecture53.6 EDA: Steering angles 06 min
Lecture53.7 Mean Baseline model: simple 05 min
Lecture53.8 Deep-learning model:Deep Learning for regression: CNN, CNN+RNN 10 min
Lecture53.9 Batch load the dataset. 06 min
Lecture53.10 NVIDIA’s end to end CNN model. 18 min
Lecture53.11 Train the model. 13 min
Lecture53.12 Test and visualize the output. 11 min
Lecture53.13 Extensions. 05 min
Lecture53.14 Assignment. 03 min
CASE STUDY 10: MUSIC GENERATION USING DEEP-LEARNING 0/11
Lecture54.1 Real-world problem 15 min
Lecture54.2 Music representation 17 min
Lecture54.3 Char-RNN with abc-notation :Char-RNN model 23 min
Lecture54.4 Char-RNN with abc-notation :Data preparation. 40 min
Lecture54.5 Char-RNN with abc-notation:Many to Many RNN ,TimeDistributed-Dense layer 18 min
Lecture54.6 Char-RNN with abc-notation : State full RNN 11 min
Lecture54.7 Char-RNN with abc-notation :Model architecture,Model training. 13 min
Lecture54.8 Char-RNN with abc-notation :Music generation. 11 min
Lecture54.9 Char-RNN with abc-notation :Generate tabla music 03 min
Lecture54.10 MIDI music generation. 04 min
Lecture54.11 Survey blog: 05 min
CASE STUDY 11: HUMAN ACTIVITY RECOGNITION 0/8
Lecture55.1 Human Activity Recognition Problem definition 09 min
Lecture55.2 Dataset understanding 22 min
Lecture55.3 Data cleaning & preprocessing 04 min
Lecture55.4 EDA:Univariate analysis. 05 min
Lecture55.5 EDA:Data visualization using t-SNE 05 min
Lecture55.6 Classical ML models. 13 min
Lecture55.7 Deep-learning Model. 15 min
Lecture55.8 Exercise: Build deeper LSTM models and hyper-param tune them 03 min
CASE STUDIES 0/4
Lecture56.1 AD-Click Predicition
Lecture56.2 Human Activity Recognition using smartphones
Lecture56.3 Song similarity and genre classification
Lecture56.4 Facebook Friend Recommendation using Graph Mining
INTERVIEW QUESTIONS 0/2
Lecture57.1 Revision Questions 30 min
Lecture57.2 Questions And Answers 30 min
Lecture57.3 External resources for Interview Questions


